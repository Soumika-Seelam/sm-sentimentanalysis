Title,Content,Score,Comments,Cleaned_Title,Sentiment
[Project] From books to presentations in 10s with AR + ML,,8379,196,project from books to presentations in s with ar  ml,0.0
[D] A Demo from 1993 of 32-year-old Yann LeCun showing off the World's first Convolutional Network for Text Recognition,,6249,135,d a demo from  of yearold yann lecun showing off the worlds first convolutional network for text recognition,0.0
[R] First Order Motion Model applied to animate paintings,,4871,109,r first order motion model applied to animate paintings,0.0
[D] This AI reveals how much time politicians stare at their phone at work,,4854,236,d this ai reveals how much time politicians stare at their phone at work,0.0
[N] AI can turn old photos into moving Images / Link is given in the comments - You can also turn your old photo like this,,4795,230,n ai can turn old photos into moving images  link is given in the comments  you can also turn your old photo like this,0.3612
[D] Types of Machine Learning Papers,,4652,213,d types of machine learning papers,0.0
I made a robot that punishes me if it detects that if I am procrastinating on my assignments [P],,4191,166,i made a robot that punishes me if it detects that if i am procrastinating on my assignments p,-0.4767
[D] The machine learning community has a toxicity problem,"It is omnipresent!

**First** of all, the peer-review process is *broken*. Every fourth NeurIPS submission is put on arXiv. There are DeepMind researchers publicly going after reviewers who are criticizing their ICLR submission. On top of that, papers by well-known institutes that were put on arXiv are accepted at top conferences, despite the reviewers agreeing on rejection. In contrast, vice versa, some papers with a majority of accepts are overruled by the AC. (I don't want to call any names, just have a look the openreview page of this year's ICRL).

**Secondly,** there is a *reproducibility crisis*. Tuning hyperparameters on the test set seem to be the standard practice nowadays. Papers that do not beat the current state-of-the-art method have a zero chance of getting accepted at a good conference. As a result, hyperparameters get tuned and subtle tricks implemented to observe a gain in performance where there isn't any.

**Thirdly,** there is a *worshiping* problem. Every paper with a Stanford or DeepMind affiliation gets praised like a breakthrough. For instance, BERT has seven times more citations than ULMfit. The Google affiliation gives so much credibility and visibility to a paper. At every ICML conference, there is a crowd of people in front of every DeepMind poster, regardless of the content of the work. The same story happened with the Zoom meetings at the virtual ICLR 2020. Moreover, NeurIPS 2020 had twice as many submissions as ICML, even though both are top-tier ML conferences. Why? Why is the name ""neural"" praised so much? Next, Bengio, Hinton, and LeCun are truly deep learning pioneers but calling them the ""godfathers"" of AI is insane. It has reached the level of a cult.

**Fourthly**, the way Yann LeCun talked about biases and fairness topics was insensitive. However, the *toxicity* and backlash that he received are beyond any reasonable quantity. Getting rid of LeCun and silencing people won't solve any issue.

**Fifthly**, machine learning, and computer science in general, have a huge *diversity problem*. At our CS faculty, only 30% of undergrads and 15% of the professors are women. Going on parental leave during a PhD or post-doc usually means the end of an academic career. However, this lack of diversity is often abused as an excuse to shield certain people from any form of criticism.  Reducing every negative comment in a scientific discussion to race and gender creates a toxic environment. People are becoming afraid to engage in fear of being called a racist or sexist, which in turn reinforces the diversity problem.

**Sixthly**, moral and ethics are set *arbitrarily*. The U.S. domestic politics dominate every discussion. At this very moment, thousands of Uyghurs are put into concentration camps based on computer vision algorithms invented by this community, and nobody seems even remotely to care. Adding a ""broader impact"" section at the end of every people will not make this stop. There are huge shitstorms because a researcher wasn't mentioned in an article. Meanwhile, the 1-billion+ people continent of Africa is virtually excluded from any meaningful ML discussion (besides a few Indaba workshops).

**Seventhly**, there is a cut-throat publish-or-perish *mentality*. If you don't publish 5+ NeurIPS/ICML papers per year, you are a looser. Research groups have become so large that the PI does not even know the name of every PhD student anymore. Certain people submit 50+ papers per year to NeurIPS. The sole purpose of writing a paper has become to having one more NeurIPS paper in your CV. Quality is secondary; passing the peer-preview stage has become the primary objective.

**Finally**, discussions have become *disrespectful*. Schmidhuber calls Hinton a thief, Gebru calls LeCun a white supremacist, Anandkumar calls Marcus a sexist, everybody is under attack, but nothing is improved.

Albert Einstein was opposing the theory of [quantum mechanics](https://en.wikipedia.org/wiki/Albert_Einstein#Einstein's_objections_to_quantum_mechanics). Can we please stop demonizing those who do not share our exact views. We are allowed to disagree without going for the jugular. 

The moment we start silencing people because of their opinion is the moment scientific and societal progress dies. 

Best intentions, Yusuf",3895,568,d the machine learning community has a toxicity problem,-0.4019
"[Project] NEW PYTHON PACKAGE: Sync GAN Art to Music with ""Lucid Sonic Dreams""! (Link in Comments)",,3711,174,project new python package sync gan art to music with lucid sonic dreams link in comments,0.4574
[P] Using oil portraits and First Order Model to bring the paintings back to life,,3494,112,p using oil portraits and first order model to bring the paintings back to life,0.0
[D] Convolution Neural Network Visualization - Made with Unity 3D and lots of Code / source - stefsietz (IG),,3413,75,d convolution neural network visualization  made with unity d and lots of code  source  stefsietz ig,0.0
[P] Doing a clone of Rocket League for AI experiments. Trained an agent to air dribble the ball.,,3256,65,p doing a clone of rocket league for ai experiments trained an agent to air dribble the ball,0.0
[R] Speech-to-speech translation for a real-world unwritten language,,3062,213,r speechtospeech translation for a realworld unwritten language,0.0
[D] Our community must get serious about opposing OpenAI,"OpenAI was founded for the explicit purpose of democratizing access to AI and acting as a counterbalance to the closed off world of big tech by developing open source tools.

They have abandoned this idea entirely.

Today, with the release of GPT4 and their direct statement that they will not release details of the model creation due to ""safety concerns"" and the competitive environment, they have created a precedent worse than those that existed before they entered the field. We're at risk now of other major players, who previously at least published their work and contributed to open source tools, close themselves off as well.

AI alignment is a serious issue that we definitely have not solved. Its a huge field with a dizzying array of ideas, beliefs and approaches. We're talking about trying to capture the interests and goals of all humanity, after all. In this space, the one approach that is horrifying (and the one that OpenAI was LITERALLY created to prevent) is a singular or oligarchy of for profit corporations making this decision for us. This is exactly what OpenAI plans to do.

I get it, GPT4 is incredible. However, we are talking about the single most transformative technology and societal change that humanity has ever made. It needs to be for everyone or else the average person is going to be left behind.

We need to unify around open source development; choose companies that contribute to science, and condemn the ones that don't.

This conversation will only ever get more important.",3029,451,d our community must get serious about opposing openai,-0.0772
[P] I made a command-line tool that explains your errors using ChatGPT (link in comments),,2883,112,p i made a commandline tool that explains your errors using chatgpt link in comments,-0.34
[P] Using Deep Learning to draw and write with your hand and webcam 👆. The model tries to predict whether you want to have 'pencil up' or 'pencil down' (see at the end of the video). You can try it online (link in comments),,2845,60,p using deep learning to draw and write with your hand and webcam  the model tries to predict whether you want to have pencil up or pencil down see at the end of the video you can try it online link in comments,0.5423
[R] Consistent Video Depth Estimation (SIGGRAPH 2020) - Links in the comments.,,2837,102,r consistent video depth estimation siggraph   links in the comments,0.0
"[R] [RIFE: 15FPS to 60FPS] Video frame interpolation , GPU real-time flow-based method",,2801,146,r rife fps to fps video frame interpolation  gpu realtime flowbased method,0.0
[R] Wolfenstein and Doom Guy upscaled into realistic faces with PULSE,,2791,104,r wolfenstein and doom guy upscaled into realistic faces with pulse,-0.4019
[P] I'm using Instruct GPT to show anti-clickbait summaries on youtube videos,,2775,249,p im using instruct gpt to show anticlickbait summaries on youtube videos,0.0
[P] I made an AI twitter bot that draws people’s dream jobs for them.,,2725,74,p i made an ai twitter bot that draws peoples dream jobs for them,0.25
[D] Types of Machine Learning Papers,,2642,92,d types of machine learning papers,0.0
Should r/MachineLearning join the reddit blackout to protest changes to their API?,"Hello there, r/MachineLearning,

Recently, Reddit has announced some [changes to their API](https://www.reddit.com/r/modnews/comments/13wshdp/api_update_continued_access_to_our_api_for/) that may have pretty serious impact on many of it's users.

[You may have already seen quite a few posts like these](https://www.reddit.com/r/ModCoord/comments/1401qw5/incomplete_and_growing_list_of_participating/) across some of the other subreddits that you browse, so we're just going to cut to the chase.

# What's Happening

Third Party Reddit apps (such as Apollo, Reddit is Fun and others) are going to become ludicrously more expensive for it's developers to run, which will in turn either kill the apps, or result in a monthly fee to the users if they choose to use one of those apps to browse. Put simply, each request to Reddit within these mobile apps will cost the developer money. The developers of Apollo [were quoted around $2 million per month](https://www.reddit.com/r/apolloapp/comments/13ws4w3/had_a_call_with_reddit_to_discuss_pricing_bad/) for the current rate of usage. The only way for these apps to continue to be viable for the developer is if you (the user) pay a monthly fee, and realistically, this is most likely going to just outright kill them. **Put simply: If you use a third party app to browse Reddit, you will most likely no longer be able to do so, or be charged a monthly fee to keep it viable.**

In lieu of what's happening, [an open letter](https://www.reddit.com/r/ModCoord/comments/13xh1e7/an_open_letter_on_the_state_of_affairs_regarding/) has been released by the broader moderation community. Part of this initiative includes a potential subreddit blackout (meaning, the subreddit will be privatized) on June 12th, lasting 24-48 hours or longer. On one hand, this is great to hopefully make enough of an impact to influence Reddit to change their minds on this. On the other hand, we usually stay out of these blackouts, and we would rather not negatively impact usage of the subreddit.

We would like to give the community a voice in this. Is this an important enough matter that r/machinelearning should fully support the protest and blackout the subreddit on June 12th? Feel free to leave your thoughts and opinions below. 

Also, please use up/downvotes for this submission to make yourself heard: upvote: r/ML should join the protest, downvote: r/ML should not join the protest.",2624,217,should rmachinelearning join the reddit blackout to protest changes to their api,0.0516
[D] An example of machine learning bias on popular. Is this specific case a problem? Thoughts?,,2598,415,d an example of machine learning bias on popular is this specific case a problem thoughts,-0.168
[D] Siraj has a new paper: 'The Neural Qubit'. It's plagiarised,"Exposed in this Twitter thread: https://twitter.com/AndrewM_Webb/status/1183150368945049605

Text, figures, tables, captions, equations (even equation numbers) are all lifted from another paper with minimal changes.

Siraj's paper: http://vixra.org/pdf/1909.0060v1.pdf

The original paper: https://arxiv.org/pdf/1806.06871.pdf

Edit: I've chosen to expose this publicly because he has a lot of fans and currently a lot of paying customers. They really trust this guy, and I don't think he's going to change.",2571,451,d siraj has a new paper the neural qubit its plagiarised,0.0
[D] A Super Harsh Guide to Machine Learning,"First, read fucking Hastie, Tibshirani, and whoever. Chapters 1-4 and 7-8. If you don't understand it, keep reading it until you do. 

You can read the rest of the book if you want. You probably should, but I'll assume you know all of it. 

Take Andrew Ng's Coursera. Do all the exercises in python and R. Make sure you get the same answers with all of them. 

Now forget all of that and read the deep learning book. Put tensorflow and pytorch on a Linux box and run examples until you get it. Do stuff with CNNs and RNNs and just feed forward NNs.

Once you do all of that, go on arXiv and read the most recent useful papers. The literature changes every few months, so keep up. 

There. Now you can probably be hired most places. If you need resume filler, so some Kaggle competitions. If you have debugging questions, use StackOverflow. If you have math questions, read more. If you have life questions, I have no idea.",2567,304,d a super harsh guide to machine learning,0.25
A little seasonal homage... [P],,2563,33,a little seasonal homage p,0.0
[R] Neural Color Transfer between Images,,2458,90,r neural color transfer between images,0.0
[R] Video of experiments from DeepMind's recent “Learning Agile Soccer Skills for a Bipedal Robot with Deep Reinforcement Learning” (OP3 Soccer) project,,2443,142,r video of experiments from deepminds recent learning agile soccer skills for a bipedal robot with deep reinforcement learning op soccer project,0.0
[D] Types of Machine Learning Papers,,2406,101,d types of machine learning papers,0.0
[P] I trained a GAN to generate photorealistic fake penises,"# This Dick Pic Does Not Exist

A StyleGAN2 model to make AI-generated dicks

**Website**

[https://thisdickpicdoesnotexist.com/](https://thisdickpicdoesnotexist.com/)

**Make your own dicks**

[Google Colab](https://colab.research.google.com/drive/1DoCxr2pYlxCRv6RmITtFWahVXsbTexYp?usp=sharing)

**Github**

[https://github.com/beezeetee/TDPDNE](https://github.com/beezeetee/TDPDNE)

*Edit:* ***Interpolation***  
u/arfafax created an interpolation notebook with the model

[Interpolation Colab Notebook](https://colab.research.google.com/drive/1-SDjR6ztiExBRmf5xzspNsA5t8y3kEXk?usp=sharing)

[Cursed Interpolation Video](https://thcf7.redgifs.com/HiddenImmaterialBrownbutterfly.webm)

&#x200B;

# But Why?

Like most men, I had the problem of too many women asking for my dick pics.

So I spent the last 2 years learning linear algebra, Bayesian statistics, and multivariable calculus so that I could finally keep up with the demand by generating thousands of fake penises with AI.

The above website features those thousands of penises, do with it what you will.

If you're curious about the machine learning, the training dataset consisted of 40k dick pics from Reddit. Specifically the subreddits: r/penis r/cock, r/dicks, r/averagepenis, r/MassiveCock, and r/tinydick to keep it well rounded.

I then cleaned the dataset by training a Mask R-CNN Model to segment out the penis, used PCA on the segment to find the tilt of the shaft, then rotated the image so the schlong was aligned with the vertical axis.

The images were then put into a [StyleGAN2 ](https://github.com/NVlabs/stylegan2)model and trained for \~9 days on a TPUv3-8.

The dataset, in case you want to see what 42,273 dick pics look like is posted in the Github.

https://preview.redd.it/txq644l8w7e51.png?width=1200&format=png&auto=webp&s=bb6687c5ec53dc9454fd8bf1eec9f45af1d5f48e",2347,274,p i trained a gan to generate photorealistic fake penises,-0.4767
[R] Adversarial Latent Autoencoders (CVPR2020 paper + code),,2344,98,r adversarial latent autoencoders cvpr paper  code,-0.3612
[D]Neural-Style-PT is capable of creating complex artworks under 20 minutes.,,2252,175,dneuralstylept is capable of creating complex artworks under  minutes,0.5859
[P] Trained an AI with ML to navigate an obstacle course from Rocket League,,2206,55,p trained an ai with ml to navigate an obstacle course from rocket league,-0.3612
[P] WebtoonMe Project: Selfie to Webtoon style,,2171,85,p webtoonme project selfie to webtoon style,0.0
"A demo of Stable Diffusion, a text-to-image model, being used in an interactive video editing application.",,2154,79,a demo of stable diffusion a texttoimage model being used in an interactive video editing application,0.296
"[P] Creating ""real"" versions of Pixar characters using the pixel2style2pixel framework. Process and links to more examples in comments.",,2139,136,p creating real versions of pixar characters using the pixelstylepixel framework process and links to more examples in comments,0.296
[P] ArcaneGAN: face portrait to Arcane style,,2066,50,p arcanegan face portrait to arcane style,0.0
[R] VToonify: Controllable High-Resolution Portrait Video Style Transfer,,2060,87,r vtoonify controllable highresolution portrait video style transfer,0.0
[R] End-to-End Referring Video Object Segmentation with Multimodal Transformers,,2028,46,r endtoend referring video object segmentation with multimodal transformers,0.0
[N] [R] Google announces Dreamix: a model that generates videos when given a prompt and an input image/video.,,2030,127,n r google announces dreamix a model that generates videos when given a prompt and an input imagevideo,0.0
"[R] GANs N' Roses: Stable, Controllable, Diverse Image to Image Translation (works for videos too!)",,2022,118,r gans n roses stable controllable diverse image to image translation works for videos too,0.3595
[R] [P] AnimeGANv2 Face Portrait v2,,1999,102,r p animeganv face portrait v,0.0
[P] Vscode extension that automatically creates a summary part of Python docstring using CodeBERT,,1982,52,p vscode extension that automatically creates a summary part of python docstring using codebert,0.2732
[R] Vid2Player: Controllable Video Sprites that Behave and Appear like Professional Tennis Players,,1958,46,r vidplayer controllable video sprites that behave and appear like professional tennis players,0.3612
[P] StyleGAN2-ADA trained on cute corgi images <3,,1950,101,p styleganada trained on cute corgi images ,0.7096
"[P] I built an app that allows you to build Image Classifiers completely on your phone. Collect data, Train models, and Preview the predictions in realtime. You can also export the model/dataset to be used anywhere else. Would love some feedback.",,1930,91,p i built an app that allows you to build image classifiers completely on your phone collect data train models and preview the predictions in realtime you can also export the modeldataset to be used anywhere else would love some feedback,0.6369
"[R][P] Runway Stable Diffusion Inpainting: Erase and Replace, add a mask and text prompt to replace objects in an image",,1870,86,rp runway stable diffusion inpainting erase and replace add a mask and text prompt to replace objects in an image,0.296
[P] DeepForSpeed: A self driving car in Need For Speed Most Wanted with just a single ConvNet to play ( inspired by nvidia ),,1864,59,p deepforspeed a self driving car in need for speed most wanted with just a single convnet to play  inspired by nvidia ,0.6808
"[N] Ian Goodfellow, Apple’s director of machine learning, is leaving the company due to its return to work policy. In a note to staff, he said “I believe strongly that more flexibility would have been the best policy for my team.” He was likely the company’s most cited ML expert.",,1836,204,n ian goodfellow apples director of machine learning is leaving the company due to its return to work policy in a note to staff he said i believe strongly that more flexibility would have been the best policy for my team he was likely the companys most cited ml expert,0.8399
[P] Toonifying a photo using StyleGAN model blending and then animating with First Order Motion. Process and variations in comments.,,1839,91,p toonifying a photo using stylegan model blending and then animating with first order motion process and variations in comments,0.0
[R] JoJoGAN: One Shot Face Stylization,,1810,52,r jojogan one shot face stylization,0.0
[P] I trained a recurrent neural network trained to draw dick doodles,"# DICK-RNN

A recurrent neural network trained to draw dicks.

Demo: https://dickrnn.github.io/

GitHub: https://github.com/dickrnn/dickrnn.github.io/

This project is a fork of Google's [sketch-rnn demo](https://magenta.tensorflow.org/assets/sketch_rnn_demo/index.html). The methodology is described in this [paper](https://arxiv.org/abs/1704.03477), and the dataset used for training is based on [Quickdraw-appendix](https://github.com/studiomoniker/Quickdraw-appendix).

# Why?

From Studio Moniker's [Quickdraw-appendix](https://studiomoniker.com/projects/do-not-draw-a-penis) project:

*In 2018 Google open-sourced the [Quickdraw data set](https://github.com/googlecreativelab/quickdraw-dataset). “The world's largest doodling data set”. The set consists of 345 categories and over 50 million drawings. For obvious reasons the data set was missing a few specific categories that people seem to enjoy drawing. This made us at Moniker think about the moral reality big tech companies are imposing on our global community and that most people willingly accept this. Therefore we decided to publish an appendix to the Google Quickdraw data set.*

I also believe that [“Doodling a penis is a light-hearted symbol for a rebellious act”](https://www.theverge.com/tldr/2019/6/17/18681733/google-ai-doodle-detector-penis-protest-moniker-mozilla) and also “think our moral compasses should not be in the hands of big tech”.

# Dick Demos

[Main Dick Demo](https://dickrnn.github.io/)

[Predict Multiple Dicks](https://dickrnn.github.io/multi.html)

[Simple Dick Demo](https://dickrnn.github.io/simple.html)

[Predict Single Dick with Temperature Adjust](https://dickrnn.github.io/predict.html)

## Example Dicks from Main Demo

The dicks are embedded in the query string after `share.html`.

Examples of sharable generated dick doodles:

[Example 1](https://dickrnn.github.io/share.html?s=f38BfXcBe3wBeHsBfH4BfX4Bdn8BfIMBdogBfIYBfYgBfogBf40BgYYBg4YBhocBiYcBhIEBlX8BhHsBg3oBgnoBgXoBgHsBf3wBf48BiowBhIQBhIIBhoABhn8Bhn4Bh3gBjHABgnoBgXsBgHsBgHoBf3IBfXgBfXsBeHYBe30Ban8BfoABfYABe4AAW2kBf2wBf2QBf24Bf2wBgHUBf3EBgHIBgHkBgHkBgnQBgXsBgnkBgXwBgnwBgX8BgoABg4EBg4IBgoQBgYMBgYMBgokBgJABf74BfosBfYYBfogBfoUBf5MBf4sBgIIAVwABgIIBgIIBgYEBgIEBgn8BiYABhX8BhX4Bgn8Bg34BgX8Bg34BgH8Bf34Bgn0AZFMBgYUBgIMBgIEBf4MBgIIBf4MAf2cBf30BgXoBgngBg3gBhHgBhHoAhXgBgncBg3sBinYBiHoAWb8Bfn8Bf38BgX8Bgn4BhH8Bhn8BjYEBh4MBhoMAMXAA)

[Example 2](https://dickrnn.github.io/share.html?s=f38BfnYBe3sBensBeX0BeX4Bdn8BfIEBfoMBfYQBfoUBf48BgIgBhIgBiosBhIABg4ABgn4Bg3wBhXkBfX8Be4IBe4MBe4QBfYUBfoQBf4kBgIUBg4YBhIUBhYMBhIABhIABhX4BhXoBhHoBg3kBgncBgHcBgHkBf3sBfn0BfX4Bfn8Bfn4BfX4Bfn4BfX4Aa0gBhHwBhnsBiXkBiXsBinsBlHkBjXsBi3wBiX0BiX4Bh34Bjn4BiX8BhX4Bg38BhX8BhX8BgH8BgH8BgYABgIABgIEBgH8BgYABgIEBgoMBgIEBgIEBgYMBgIIBgYUBf4MBfoUBfYEBfIEBdYQBd4IBb4MBeIABd4EBd4EBZoQBbYUBdoIBd4IBeoEBdYIBeIEBeoABe4EBe4EBfYABfYABfn8BfoABfoABf38Bf38A/ikBf38Bf38Bf4EBf4QBgIQBgYMBgIEBgoMBgIEBgoQBgYEBgIEBgYEBgYEBf38Bf38Bf4AAhmsBf38Bf4ABf38Bf38Bf38Bf38Bf34Bf38Bf34Bf38Bf34Bfn8Bf38AipkA)

[Example 3](https://dickrnn.github.io/share.html?s=f38Bh30BjH8BkIMBjYQBhoQBgIgBf4sBe40BeoYBeoUBeoIBeIEBd4ABd38BdnkBeXkBe3cBe3UBfHUBenMBgn0BhH0BhHsBgn0AxocBgH8Bgn4BjHwBiH0BhX8Bgn8Bh4IBhYQBhoUBhYcBhIgBgYYBf4YBf4cBf4EBfIMBeoMBdoMBdYEBdoABd38BeH0Bd3sBensBdXEBfHcBfXcBfngBf3gAcmEBf34BgX4BgXsBgXgBgXIBgHcBgWYBgHUBf3UBgHABf3oBfnsBfnsBfnoBf30BgHwBgXsBgX0BgnwBg3wBiHoBiHsBgn4Bg38BhX8BgYABgoEBgYIBgIIBgYcBgYkBgIQBf4YBf4QBf4kBf4UBf4QBf4MBf4MBf4QBf4QBf4QBfoUBfYQBfoUBf4IBfYcBfYoBf4IBfoYBfoMBfoMBf4EAbAABf4MBf4EBf4IBf4ABfoMBf38Bf4AAfH0BgX8Bk4IBg4ABgn8BgoABgoAASrIA)

[Example 4](https://dickrnn.github.io/share.html?s=f38BZn8BdIUBdokBeo0BfY8BfpQBhY4BiowBj4YBkIEBlH8BjHkBi3IBiXEBgnUBgXkBf6YBgYwBhYkBi4gBjYIBjIEBi38BiHkBh3UBg3MBgm0BgXIBfnMBenUBenkBdXUAAEcBhH8BhXkBiXgBi3IBkG4BkHEBk28Bk3IBnmYBi3gBi3oBk3kBiX8BioIBjYkBh4kBhYwBgYkBgY0BfY4BdZEBc48Bd4gBd4cBcYoBd4UAMDEBf4EBgoABiocBk4gBlIUBjX8Bh34BhXoAZEMBe3wBfHsBfH4BfX0BfX0AtJQBin8BhX0BhX8Bf34AqHoBf30BgX4BhXIBgn0BinUAhXoBfn8BhH4Bj3oBlXgBjH8BjYMAkKUBhH8BloQBh4IBjYUAapkBjXkBpHoBkH8Ac8YBhYcBhocBiYsBh4sBhIgARGgA)

# Dataset

This recurrent neural network was trained on a [dataset](https://github.com/studiomoniker/Quickdraw-appendix) of roughly 10,000 dick doodles.",1785,119,p i trained a recurrent neural network trained to draw dick doodles,-0.5106
"[P] Cross-Model Interpolations between 5 StyleGanV2 models - furry, FFHQ, anime, ponies, and a fox model",,1781,104,p crossmodel interpolations between  styleganv models  furry ffhq anime ponies and a fox model,0.0
[P] stablediffusion-infinity: Outpainting with Stable Diffusion on an infinite canvas,,1760,60,p stablediffusioninfinity outpainting with stable diffusion on an infinite canvas,0.296
[R] WHIRL algorithm: Robot performs diverse household tasks via exploration after watching one human video (link in comments),,1741,70,r whirl algorithm robot performs diverse household tasks via exploration after watching one human video link in comments,0.2263
[R] It’s wild to see an AI literally eyeballing raytracing based on 100 photos to create a 3d scene you can step inside ☀️ Low key getting addicted to NeRF-ing imagery datasets🤩,,1749,82,r its wild to see an ai literally eyeballing raytracing based on  photos to create a d scene you can step inside  low key getting addicted to nerfing imagery datasets,0.0
"[P] AppleNeuralHash2ONNX: Reverse-Engineered Apple NeuralHash, in ONNX and Python","As you may already know Apple is going to implement NeuralHash algorithm for on-device [CSAM detection](https://www.apple.com/child-safety/pdf/CSAM_Detection_Technical_Summary.pdf) soon. Believe it or not, this algorithm already exists as early as iOS 14.3, hidden under obfuscated class names. After some digging and reverse engineering on the hidden APIs I managed to export its model (which is MobileNetV3) to ONNX and rebuild the whole NeuralHash algorithm in Python. You can now try NeuralHash even on Linux!

Source code: [https://github.com/AsuharietYgvar/AppleNeuralHash2ONNX](https://github.com/AsuharietYgvar/AppleNeuralHash2ONNX)

No pre-exported model file will be provided here for obvious reasons. But it's very easy to export one yourself following the guide I included with the repo above. You don't even need any Apple devices to do it.

Early tests show that it can tolerate image resizing and compression, but not cropping or rotations.

Hope this will help us understand NeuralHash algorithm better and know its potential issues before it's enabled on all iOS devices.

Happy hacking!",1735,224,p appleneuralhashonnx reverseengineered apple neuralhash in onnx and python,0.0
[P] Realtime multihand pose estimation demo,,1726,128,p realtime multihand pose estimation demo,0.0
"[D] I don't really trust papers out of ""Top Labs"" anymore","I mean, I trust that the numbers they got are accurate and that they really did the work and got the results. I believe those. It's just that, take the recent ""An Evolutionary Approach to Dynamic Introduction of Tasks in Large-scale Multitask Learning Systems"" paper. It's 18 pages of talking through this pretty convoluted evolutionary and multitask learning algorithm, it's pretty interesting, solves a bunch of problems. But two notes. 

One, the big number they cite as the success metric is 99.43 on CIFAR-10, against a SotA of 99.40, so woop-de-fucking-doo in the grand scheme of things.

Two, there's a chart towards the end of the paper that details how many TPU core-hours were used for just the training regimens that results in the final results. The sum total is 17,810 core-hours. Let's assume that for someone who doesn't work at Google, you'd have to use on-demand pricing of $3.22/hr. This means that these trained models cost $57,348. 

Strictly speaking, throwing enough compute at a general enough genetic algorithm will eventually produce arbitrarily good performance, so while you can absolutely read this paper and collect interesting ideas about how to use genetic algorithms to accomplish multitask learning by having each new task leverage learned weights from previous tasks by defining modifications to a subset of components of a pre-existing model, there's a meta-textual level on which this paper is just ""Jeff Dean spent enough money to feed a family of four for half a decade to get a 0.03% improvement on CIFAR-10.""

OpenAI is far and away the worst offender here, but it seems like everyone's doing it. You throw a fuckton of compute and a light ganache of new ideas at an existing problem with existing data and existing benchmarks, and then if your numbers are infinitesimally higher than their numbers, you get to put a lil' sticker on your CV. Why should I trust that your ideas are even any good? I can't check them, I can't apply them to my own projects. 

Is this really what we're comfortable with as a community? A handful of corporations and the occasional university waving their dicks at everyone because they've got the compute to burn and we don't? There's a level at which I think there should be a new journal, exclusively for papers in which you can replicate their experimental results in under eight hours on a single consumer GPU.",1695,262,d i dont really trust papers out of top labs anymore,-0.2775
[P] I built a chatbot that lets you talk to any Github repository,,1689,156,p i built a chatbot that lets you talk to any github repository,0.0
[R] Deep Image Analogy,,1691,119,r deep image analogy,0.0
[P] The easiest way to process and tag video data,,1683,55,p the easiest way to process and tag video data,0.4215
[P] Pose Animator: SVG animation tool using real-time human perception TensorFlow.js models (links in comments),,1674,31,p pose animator svg animation tool using realtime human perception tensorflowjs models links in comments,0.0
[D] Why can't you guys comment your fucking code?,"Seriously.

I spent the last few years doing web app development. Dug into DL a couple months ago. Supposedly, compared to the post-post-post-docs doing AI stuff, JavaScript developers should be inbred peasants. But every project these peasants release, even a fucking library that colorizes CLI output, has a catchy name, extensive docs, shitloads of comments, fuckton of tests, semantic versioning, changelog, and, oh my god, better variable names than `ctx_h` or `lang_hs` or `fuck_you_for_trying_to_understand`.

The concepts and ideas behind DL, GANs, LSTMs, CNNs, whatever – it's clear, it's simple, it's intuitive. The slog is to go through the jargon (that keeps changing beneath your feet - what's the point of using fancy words if you can't keep them consistent?), the unnecessary equations, trying to squeeze meaning from bullshit language used in papers, figuring out the super important steps, preprocessing, hyperparameters optimization that the authors, oops, failed to mention.

Sorry for singling out, but [look at this](https://github.com/facebookresearch/end-to-end-negotiator/blob/master/src/agent.py) - what the fuck? If a developer anywhere else at Facebook would get this code for a review they would throw up.

- Do you intentionally try to obfuscate your papers? Is pseudo-code a fucking premium? Can you at least try to give some intuition before showering the reader with equations?

- How the fuck do you dare to release a paper without source code?

- Why the fuck do you never ever add comments to you code?

- When naming things, are you charged by the character? Do you get a bonus for acronyms?

- Do you realize that OpenAI having needed to release a ""baseline"" TRPO implementation is a fucking disgrace to your profession?

- Jesus christ, who decided to name a tensor concatenation function `cat`?
",1655,476,d why cant you guys comment your fucking code,0.0
[P] YoHa: A practical hand tracking engine.,,1630,61,p yoha a practical hand tracking engine,0.4939
[P] I made Communities: a library of clustering algorithms for network graphs (link in comments),,1616,40,p i made communities a library of clustering algorithms for network graphs link in comments,0.0
"[P] I built Adrenaline, a debugger that fixes errors and explains them with GPT-3",,1572,92,p i built adrenaline a debugger that fixes errors and explains them with gpt,-0.34
[R] Video Demo of “Drag Your GAN: Interactive Point-based Manipulation on the Generative Image Manifold”,,1532,44,r video demo of drag your gan interactive pointbased manipulation on the generative image manifold,-0.296
[R] AI Learns Playing Basketball Just Like Humans! [https://www.youtube.com/watch?v=Rzj3k3yerDk],,1505,87,r ai learns playing basketball just like humans httpswwwyoutubecomwatchvrzjkyerdk,0.5562
[D] Does anybody else despise OpenAI?," I  mean, don't get me started with the closed source models they have that were trained using the work of unassuming individuals who will never  see a penny for it. Put it up on Github they said. I'm all for  open-source, but when a company turns around and charges you for a  product they made with freely and publicly made content, while forbidding you from using the output to create competing models, that is where I  draw the line. It is simply ridiculous. 

Sam Altman couldn't be anymore predictable with his recent attempts to get the government to start regulating AI.

What  risks? The AI is just a messenger for information that is already out  there if one knows how/where to look. You don't need AI to learn how to  hack, to learn how to make weapons, etc. Fake news/propaganda? The  internet has all of that covered. LLMs are no where near the level of AI  you see in sci-fi. I mean, are people really afraid of text? Yes, I  know that text can sometimes be malicious code such as viruses, but  those can be found on github as well.  If they fall for this they might  as well shutdown the internet while they're at it.

He  is simply blowing things out of proportion and using fear to increase  the likelihood that they do what he wants, hurt the competition. I  bet he is probably teething with bitterness everytime a new huggingface  model comes out. The thought of us peasants being able to use AI  privately is too dangerous. No, instead we must be fed scraps while they  slowly take away our jobs and determine our future.

This  is not a doomer post, as I am all in favor of the advancement of AI.  However, the real danger here lies in having a company like OpenAI  dictate the future of humanity. I get it, the writing is on the wall;  the cost of human intelligence will go down, but if everyone has their  personal AI then it wouldn't seem so bad or unfair would it? Listen,  something that has the power to render a college degree that costs  thousands of dollars worthless should be available to the public. This  is to offset the damages and job layoffs that will come as a result of  such an entity. It wouldn't be as bitter of a taste as it would if you were replaced by it while still not being able to access it. Everyone should be able to use it as leverage, it is the only fair solution.

If  we don't take action now, a company like ClosedAI will, and they are  not in favor of the common folk. Sam Altman is so calculated to the  point where there were times when he seemed to be shooting OpenAI in the foot during his talk.  This move is to simply conceal his real intentions, to climb the ladder and take it with him. If he didn't include his company in his  ramblings, he would be easily read. So instead, he pretends to be scared of his own product, in an effort to legitimize his claim. Don't fall  for it.

They are slowly making a  reputation as one the most hated tech companies, right up there with  Adobe, and they don't show any sign of change. They have no moat,  othewise they wouldn't feel so threatened to the point where they would have to resort to creating barriers of entry via regulation. This only  means one thing, we are slowly catching up. We just need someone to  vouch for humanity's well-being, while acting as an opposing force to the  evil corporations who are only looking out for themselves. Question is,  who would be a good candidate?",1491,427,d does anybody else despise openai,-0.34
[D] The current and future state of AI/ML is shockingly demoralizing with little hope of redemption,"I recently encountered the PaLM (Scaling Language Modeling with Pathways) paper from Google Research and it opened up a can of worms of ideas I’ve felt I’ve intuitively had for a while, but have been unable to express – and I know I can’t be the only one. Sometimes I wonder what the original pioneers of AI – Turing, Neumann, McCarthy, etc. – would think if they could see the state of AI that we’ve gotten ourselves into. 67 authors, 83 pages, 540B parameters in a model, the internals of which no one can say they comprehend with a straight face, 6144 TPUs in a commercial lab that no one has access to, on a rig that no one can afford, trained on a volume of data that a human couldn’t process in a lifetime, 1 page on ethics with the same ideas that have been rehashed over and over elsewhere with no attempt at a solution – bias, racism, malicious use, etc. – for purposes that who asked for?

When I started my career as an AI/ML research engineer 2016, I was most interested in two types of tasks – 1.) those that most humans could do but that would universally be considered tedious and non-scalable. I’m talking image classification, sentiment analysis, even document summarization, etc. 2.) tasks that humans lack the capacity to perform as well as computers for various reasons – forecasting, risk analysis, game playing, and so forth. I still love my career, and I try to only work on projects in these areas, but it’s getting harder and harder.

This is because, somewhere along the way, it became popular and unquestionably acceptable to push AI into domains that were originally uniquely human, those areas that sit at the top of Maslows’s hierarchy of needs in terms of self-actualization – art, music, writing, singing, programming, and so forth. These areas of endeavor have negative logarithmic ability curves – the vast majority of people cannot do them well at all, about 10% can do them decently, and 1% or less can do them extraordinarily. The little discussed problem with AI-generation is that, without extreme deterrence, we will sacrifice human achievement at the top percentile in the name of lowering the bar for a larger volume of people, until the AI ability range is the norm. This is because relative to humans, AI is cheap, fast, and infinite, to the extent that investments in human achievement will be watered down at the societal, educational, and individual level with each passing year. And unlike AI gameplay which superseded humans decades ago, we won’t be able to just disqualify the machines and continue to play as if they didn’t exist.

Almost everywhere I go, even this forum, I encounter almost universal deference given to current SOTA AI generation systems like GPT-3, CODEX, DALL-E, etc., with almost no one extending their implications to its logical conclusion, which is long-term convergence to the mean, to mediocrity, in the fields they claim to address or even enhance. If you’re an artist or writer and you’re using DALL-E or GPT-3 to “enhance” your work, or if you’re a programmer saying, “GitHub Co-Pilot makes me a better programmer?”, then how could you possibly know? You’ve disrupted and bypassed your own creative process, which is thoughts -> (optionally words) -> actions -> feedback -> repeat, and instead seeded your canvas with ideas from a machine, the provenance of which you can’t understand, nor can the machine reliably explain. And the more you do this, the more you make your creative processes dependent on said machine, until you must question whether or not you could work at the same level without it.

When I was a college student, I often dabbled with weed, LSD, and mushrooms, and for a while, I thought the ideas I was having while under the influence were revolutionary and groundbreaking – that is until took it upon myself to actually start writing down those ideas and then reviewing them while sober, when I realized they weren’t that special at all. What I eventually determined is that, under the influence, it was impossible for me to accurately evaluate the drug-induced ideas I was having because the influencing agent the generates the ideas themselves was disrupting the same frame of reference that is responsible evaluating said ideas. This is the same principle of – if you took a pill and it made you stupider, would even know it? I believe that, especially over the long-term timeframe that crosses generations, there’s significant risk that current AI-generation developments produces a similar effect on humanity, and we mostly won’t even realize it has happened, much like a frog in boiling water. If you have children like I do, how can you be aware of the the current SOTA in these areas, project that 20 to 30 years, and then and tell them with a straight face that it is worth them pursuing their talent in art, writing, or music? How can you be honest and still say that widespread implementation of auto-correction hasn’t made you and others worse and worse at spelling over the years (a task that even I believe most would agree is tedious and worth automating).

Furthermore, I’ve yet to set anyone discuss the train – generate – train - generate feedback loop that long-term application of AI-generation systems imply. The first generations of these models were trained on wide swaths of web data generated by humans, but if these systems are permitted to continually spit out content without restriction or verification, especially to the extent that it reduces or eliminates development and investment in human talent over the long term, then what happens to the 4th or 5th generation of models? Eventually we encounter this situation where the AI is being trained almost exclusively on AI-generated content, and therefore with each generation, it settles more and more into the mean and mediocrity with no way out using current methods. By the time that happens, what will we have lost in terms of the creative capacity of people, and will we be able to get it back?

By relentlessly pursuing this direction so enthusiastically, I’m convinced that we as AI/ML developers, companies, and nations are past the point of no return, and it mostly comes down the investments in time and money that we’ve made, as well as a prisoner’s dilemma with our competitors. As a society though, this direction we’ve chosen for short-term gains will almost certainly make humanity worse off, mostly for those who are powerless to do anything about it – our children, our grandchildren, and generations to come.

If you’re an AI researcher or a data scientist like myself, how do you turn things back for yourself when you’ve spent years on years building your career in this direction? You’re likely making near or north of $200k annually TC and have a family to support, and so it’s too late, no matter how you feel about the direction the field has gone. If you’re a company, how do you standby and let your competitors aggressively push their AutoML solutions into more and more markets without putting out your own? Moreover, if you’re a manager or thought leader in this field like Jeff Dean how do you justify to your own boss and your shareholders your team’s billions of dollars in AI investment while simultaneously balancing ethical concerns? You can’t – the only answer is bigger and bigger models, more and more applications, more and more data, and more and more automation, and then automating that even further. If you’re a country like the US, how do responsibly develop AI while your competitors like China single-mindedly push full steam ahead without an iota of ethical concern to replace you in numerous areas in global power dynamics? Once again, failing to compete would be pre-emptively admitting defeat.

Even assuming that none of what I’ve described here happens to such an extent, how are so few people not taking this seriously and discounting this possibility? If everything I’m saying is fear-mongering and non-sense, then I’d be interested in hearing what you think human-AI co-existence looks like in 20 to 30 years and why it isn’t as demoralizing as I’ve made it out to be.

&#x200B;

EDIT: Day after posting this -- this post took off way more than I expected. Even if I received 20 - 25 comments, I would have considered that a success, but this went much further. Thank you to each one of you that has read this post, even more so if you left a comment, and triply so for those who gave awards! I've read almost every comment that has come in (even the troll ones), and am truly grateful for each one, including those in sharp disagreement. I've learned much more from this discussion with the sub than I could have imagined on this topic, from so many perspectives. While I will try to reply as many comments as I can, the sheer comment volume combined with limited free time between work and family unfortunately means that there are many that I likely won't be able to get to. That will invariably include some that I would love respond to under the assumption of infinite time, but I will do my best, even if the latency stretches into days. Thank you all once again!",1474,400,d the current and future state of aiml is shockingly demoralizing with little hope of redemption,0.228
"[R] Clova AI Research's StarGAN v2 (CVPR 2020 + code, pre-trained models, datasets)",,1474,59,r clova ai researchs stargan v cvpr   code pretrained models datasets,0.0
[Project] From any text-dataset to valuable insights in seconds with Texthero,,1473,79,project from any textdataset to valuable insights in seconds with texthero,0.4767
"[N] [P] Google Deepmind released an album with ""visualizations of AI"" to combat stereotypical depictions of glowing brains, blue screens, etc.",,1465,131,n p google deepmind released an album with visualizations of ai to combat stereotypical depictions of glowing brains blue screens etc,-0.34
[R] SIMPLERECON — 3D Reconstruction without 3D Convolutions — 73ms per frame !,,1421,35,r simplerecon  d reconstruction without d convolutions  ms per frame ,0.0
[P] Keras Implementation of Image Outpaint,,1408,89,p keras implementation of image outpaint,0.0
[News] New Google tech - Geospatial API uses computer vision and machine learning to turn 15 years of street view imagery into a 3d canvas for augmented reality developers,,1406,38,news new google tech  geospatial api uses computer vision and machine learning to turn  years of street view imagery into a d canvas for augmented reality developers,0.25
[R] RigNet: Neural Rigging for Articulated Characters,,1402,37,r rignet neural rigging for articulated characters,0.0
[D] Anyone else witnessing a panic inside NLP orgs of big tech companies?,"I'm in a big tech company working along side a science team for a product you've all probably used. We have these year long initiatives to productionalize ""state of the art NLP models"" that are now completely obsolete in the face of GPT-4. I think at first the science orgs were quiet/in denial. But now it's very obvious we are basically working on worthless technology. And by ""we"", I mean a large organization with scores of teams. 

Anyone else seeing this? What is the long term effect on science careers that get disrupted like this? Whats even more odd is the ego's of some of these science people

Clearly the model is not a catch all, but still",1373,482,d anyone else witnessing a panic inside nlp orgs of big tech companies,-0.5106
"[D] Siraj Raval - Potentially exploiting students, banning students asking for refund. Thoughts?","I'm not a personal follower of Siraj, but this issue came up in a ML FBook group that I'm part of. I'm curious to hear what you all think.

It appears that Siraj recently offered a course ""Make Money with Machine Learning"" with a registration fee but did not follow through with promises made in the initial offering of the course. On top of that, he created a refund and warranty page with information regarding the course *after* people already paid. Here is a link to a WayBackMachine captures of u/klarken's documentation of Siraj's potential misdeeds: [case for a refund](https://web.archive.org/save/https://case-for-a-refund.s3.us-east-2.amazonaws.com/feedback.html), [discussion in course Discord](https://web.archive.org/web/20190923211614/https://case-for-a-refund.s3.us-east-2.amazonaws.com/reference_messages.png), [\~1200 individuals in the course](https://web.archive.org/web/20190923211815/https://case-for-a-refund.s3.us-east-2.amazonaws.com/members.png), [Multiple Slack channel discussion, students hidden from each other](https://web.archive.org/web/20190923211940/https://case-for-a-refund.s3.us-east-2.amazonaws.com/multiple_slack_channels.png), [""Hundreds refunded""](https://web.archive.org/web/20190923212113/https://case-for-a-refund.s3.us-east-2.amazonaws.com/hundreds_refunded.png)

According to Twitter threads, he has been banning anyone in his Discord/Slack that has been asking for refunds.

On top of this there are many Twitter threads regarding his behavior. A screenshot (bottom of post) of an account that has since been deactivated/deleted (he made the account to try and get Siraj's attention). Here is a Twitter WayBackMachine archive link of a search for the user in the screenshot: [https://web.archive.org/web/20190921130513/https:/twitter.com/search?q=safayet96434935&src=typed\_query](https://web.archive.org/web/20190921130513/https:/twitter.com/search?q=safayet96434935&src=typed_query). In the search results it is apparent that there are many students who have been impacted by Siraj.

UPDATE 1: Additional searching on Twitter has yielded many more posts, check out the tweets/retweets of these people: [student1](https://web.archive.org/save/https:/twitter.com/ReneeSLiu1) [student2](https://web.archive.org/web/20190921133155/https://twitter.com/Aravind56898077)

UPDATE 2: A user mentioned that I should ask a question on r/legaladvice regarding the legality of the refusal to refund and whatnot. I have done so [here](https://www.reddit.com/r/legaladvice/comments/d7gopa/independent_online_course_false_advertising_and/). It appears that per California commerce law (where the School of AI is registered) individuals have the right to ask for a refund for 30 days.

UPDATE 3: Siraj has replied to the post below, and on [Twitter](https://web.archive.org/web/20190922213957/https://twitter.com/sirajraval/status/1175864213916372992?s=09) (Way Back Machine capture)

UPDATE 4: Another student has shared their interactions via [this Imgur post](https://imgur.com/gallery/msAdqBn). And another recorded moderators actively suppressing any mentions of refunds [on a live stream](https://web.archive.org/save/https://imgur.com/a/o1TMRY2). [Here is an example](https://imgur.com/a/KhMV6Xo) of assignment quality, note that the assignment is to generate fashion designs not pneumonia prediction.

UPDATE5: Relevant Reddit posts: [Siraj response](https://www.reddit.com/r/MachineLearning/comments/d7vv1l/d_siraj_apologizes_and_promises_refunds_within_30/), [question about opinions on course two weeks before this](https://www.reddit.com/r/learnmachinelearning/comments/cp7kht/guys_what_do_you_think_about_siraj_ravals_new/ewnv00m/?utm_source=share&utm_medium=web2x), [Siraj-Udacity relationship](https://www.reddit.com/r/MachineLearning/comments/d8nlqf/n_udacity_had_an_interventional_meeting_with/)

UPDATE6: The Register has [published a piece on the debacle](https://www.theregister.co.uk/2019/09/27/youtube_ai_star/), Coffezilla [posted a video on all of this](https://www.youtube.com/watch?v=7jmBE4yPrOs)

UPDATE7: Example of blatant ripoff: GitHub user gregwchase [diabetic retinopathy](https://github.com/gregwchase/dsi-capstone), Siraj's [ripoff](https://web.archive.org/web/20190928160728/https://github.com/llSourcell/AI_in_Medicine_Clinical_Imaging_Classification)

UPDATE8: Siraj has a [new paper and it is plagiarized](https://www.reddit.com/r/MachineLearning/comments/dh2xfs/d_siraj_has_a_new_paper_the_neural_qubit_its/)

If you were/are a student in the course and have your own documentation of your interactions, please feel free to bring them to my attention either via DM or in the comments below and I will add them to the main body here.

&#x200B;

https://preview.redd.it/i75r44bku7o31.jpg?width=347&format=pjpg&auto=webp&s=ec2f02ee1998e27ea00d529ffb2086657dc60d77",1358,468,d siraj raval  potentially exploiting students banning students asking for refund thoughts,-0.4404
[P] Predict your political leaning from your reddit comment history! (Webapp linked in comments),,1352,188,p predict your political leaning from your reddit comment history webapp linked in comments,0.0
"So long r/MachineLearning, it's been an interesting few years","Some of you may recognize me, most of you probably don't. I've been the most active moderator of r/MachineLearning for a few years now, but on June 30th I'll be deleting my Reddit account.

I pretty much exclusively used Apollo to moderate. It would notify me of any new post, which allowed me to moderate from anywhere, anytime. That's how I stayed on top of moderating such a large sub.

When I stepped back on my moderation efforts a few months ago, [the effects](https://old.reddit.com/r/MachineLearning/comments/110swn2/d_quality_of_posts_in_this_sub_going_down) were quite apparent to [many of you](https://old.reddit.com/r/MachineLearning/comments/115ez2r/deleted_by_user).

Of course, this is the internet, and each of you have your own subjective view on moderation. Just know that it is a very time consuming task that I did for free because I genuinely cared about the community.

If you want to join me, I'll be moving on to kbin where I'm a moderator for [m/machinelearning](https://kbin.social/m/machinelearning). Otherwise, this is my farewell.

P.S. I'm sure there will be some who are sympathetic and some who just have an axe to grind and will complain about anything. I'm not a piñata; there's no prize inside if you bash me, but if you just can't help yourself, then have at it. I'll be gone soon anyway.",1319,90,so long rmachinelearning its been an interesting few years,0.4019
[R] AlphaFold 2,"Seems like DeepMind just caused the ImageNet moment for protein folding.

Blog post isn't that deeply informative yet (paper is promised to appear soonish). Seems like the improvement over the first version of AlphaFold is mostly usage of transformer/attention mechanisms applied to residue space and combining it with the working ideas from the first version. Compute budget is surprisingly moderate given how crazy the results are. Exciting times for people working in the intersection of molecular sciences and ML :)

Tweet by Mohammed AlQuraishi (well-known domain expert)  
[https://twitter.com/MoAlQuraishi/status/1333383634649313280](https://twitter.com/MoAlQuraishi/status/1333383634649313280)

DeepMind BlogPost  
[https://deepmind.com/blog/article/alphafold-a-solution-to-a-50-year-old-grand-challenge-in-biology](https://deepmind.com/blog/article/alphafold-a-solution-to-a-50-year-old-grand-challenge-in-biology)  


UPDATE:   
Nature published a comment on it as well  
[https://www.nature.com/articles/d41586-020-03348-4](https://www.nature.com/articles/d41586-020-03348-4)",1317,240,r alphafold ,0.0
[P] Generative Ramen,,1316,76,p generative ramen,0.0
[P] Run Stable Diffusion locally with a web UI + artist workflow video,,1306,53,p run stable diffusion locally with a web ui  artist workflow video,0.296
"[D] If you had to show one paper to someone to show that machine learning is beautiful, what would you choose? (assuming they're equipped to understand it)",,1307,278,d if you had to show one paper to someone to show that machine learning is beautiful what would you choose assuming theyre equipped to understand it,0.5994
[Project] These plants do not exist - Using StyleGan2,,1304,26,project these plants do not exist  using stylegan,0.0
AMA: We are the Google Brain team. We'd love to answer your questions about machine learning.,"We’re a group of research scientists and engineers that work on the [Google Brain team](http://g.co/brain).  Our group’s mission is to make intelligent machines, and to use them to improve people’s lives.  For the last five years, we’ve conducted research and built systems to advance this mission.

We disseminate our work in multiple ways:

* By publishing papers about our research (see [publication list](https://research.google.com/pubs/BrainTeam.html))
* By building and open-sourcing software systems like TensorFlow (see [tensorflow.org](http://tensorflow.org) and [https://github.com/tensorflow/tensorflow](https://github.com/tensorflow/tensorflow))
* By working with other teams at Google and Alphabet to get our work into the hands of billions of people (some examples: [RankBrain for Google Search](https://en.wikipedia.org/wiki/RankBrain), [SmartReply for GMail](https://research.googleblog.com/2015/11/computer-respond-to-this-email.html), [Google Photos](https://research.googleblog.com/2014/09/building-deeper-understanding-of-images.html), [Google Speech Recognition](https://research.googleblog.com/2012/08/speech-recognition-and-deep-learning.html), …)
* By training new researchers through internships and the [Google Brain Residency](http://g.co/brainresidency) program

We are:

* [Jeff Dean](http://research.google.com/people/jeff) (/u/jeffatgoogle)
* [Geoffrey Hinton](https://research.google.com/pubs/GeoffreyHinton.html) (/u/geoffhinton)
* [Vijay Vasudevan](http://research.google.com/pubs/VijayVasudevan.html) (/u/Spezzer)
* [Vincent Vanhoucke](http://research.google.com/pubs/VincentVanhoucke.html) (/u/vincentvanhoucke)
* [Chris Olah](http://research.google.com/pubs/ChristopherOlah.html) (/u/colah)
* [Rajat Monga](http://research.google.com/pubs/RajatMonga.html) (/u/rajatmonga)
* [Greg Corrado](http://research.google.com/pubs/GregCorrado.html) (/u/gcorrado)
* [George Dahl](https://scholar.google.com/citations?user=ghbWy-0AAAAJ&hl=en) (/u/gdahl)
* [Doug Eck](http://research.google.com/pubs/author39086.html) (/u/douglaseck)
* [Samy Bengio](http://research.google.com/pubs/bengio.html) (/u/samybengio)
* [Quoc Le](http://research.google.com/pubs/QuocLe.html) (/u/quocle)
* [Martin Abadi](http://research.google.com/pubs/abadi.html) (/u/martinabadi)
* [Claire Cui](https://www.linkedin.com/in/claire-cui-5021035) (/u/clairecui)
* [Anna Goldie](https://www.linkedin.com/in/adgoldie) (/u/anna_goldie)
* [Zak Stone](https://www.linkedin.com/in/zstone) (/u/poiguy)
* [Dan Mané](https://www.linkedin.com/in/danmane) (/u/danmane)
* [David Patterson](https://www2.eecs.berkeley.edu/Faculty/Homepages/patterson.html) (/u/pattrsn)
* [Maithra Raghu](http://maithraraghu.com/) (/u/mraghu)
* [Anelia Angelova](http://research.google.com/pubs/AneliaAngelova.html) (/u/aangelova)
* [Fernanda Viégas](http://hint.fm/) (/u/fernanda_viegas)
* [Martin Wattenberg](http://hint.fm/) (/u/martin_wattenberg)
* [David Ha](http://blog.otoro.net/) (/u/hardmaru)
* [Sherry Moore](https://www.linkedin.com/in/sherry-moore-38b3a32) (/u/sherryqmoore/)
* … and maybe others: we’ll update if others become involved.

We’re excited to answer your questions about the Brain team and/or machine learning!  (We’re gathering questions now and will be answering them on August 11, 2016).

Edit (~10 AM Pacific time): A number of us are gathered in Mountain View, San Francisco, Toronto, and Cambridge (MA), snacks close at hand.  Thanks for all the questions, and we're excited to get this started.

Edit2: We're back from lunch.  Here's [our AMA command center](http://imgur.com/gallery/zHkoC)

Edit3: (2:45 PM Pacific time): We're mostly done here.  Thanks for the questions, everyone!  We may continue to answer questions sporadically throughout the day.",1305,791,ama we are the google brain team wed love to answer your questions about machine learning,0.6369
[P] I made a browser extension that uses ChatGPT to answer every StackOverflow question,,1304,133,p i made a browser extension that uses chatgpt to answer every stackoverflow question,0.0
[P] Landing the Falcon booster with Reinforcement Learning in OpenAI,,1292,55,p landing the falcon booster with reinforcement learning in openai,0.0
[P] Football Player 3D Pose Estimation using YOLOv7,,1289,44,p football player d pose estimation using yolov,0.0
"[N] 4 Months after Siraj was caught scamming he has still not refunded any victims based in India, Philippines, or any other countries with no legal recourse. He makes an apology video, and when his victims ask for their refund, his followers respond with ""Be kind. He's asking for your forgiveness""","This is fucking sick..

People based in India, the Philippines, and other countries that do not have the resources to go after Siraj legally are those who need the money the most. 200$ could be a months worth of salary, or several months. And the types of people who get caught up in the scams are those who genuinely looking to improve their financial situation and work hard for it. This is fucking **cruel**. 

I'm having a hard time believing Siraj's followers are that brainwashed. Most likely alt accounts controlled by Siraj.

https://i.imgur.com/6cUhQDO.png

https://i.imgur.com/TDx5ELA.png",1286,174,n  months after siraj was caught scamming he has still not refunded any victims based in india philippines or any other countries with no legal recourse he makes an apology video and when his victims ask for their refund his followers respond with be kind hes asking for your forgiveness,0.6114
"[D] The ""it"" in AI models is really just the dataset?",,1283,275,d the it in ai models is really just the dataset,0.0
[N]: Dall-E 2 Explained,,1278,68,n dalle  explained,0.0
[P] OpenAssistant - The world's largest open-source replication of ChatGPT,"We’re excited to announce the release of OpenAssistant.

The future of AI development depends heavily on high quality datasets and models being made publicly available, and that’s exactly what this project does.

Watch the annoucement video:

[https://youtu.be/ddG2fM9i4Kk](https://youtu.be/ddG2fM9i4Kk)

&#x200B;

Our team has worked tirelessly over the past several months collecting large amounts of text-based input and feedback to create an incredibly diverse and unique dataset designed specifically for training language models or other AI applications.

With over 600k human-generated data points covering a wide range of topics and styles of writing, our dataset will be an invaluable tool for any developer looking to create state-of-the-art instruction models!

To make things even better, we are making this entire dataset free and accessible to all who wish to use it. Check it out today at our HF org: OpenAssistant

On top of that, we've trained very powerful models that you can try right now at: [open-assistant.io/chat](https://open-assistant.io/chat) !",1273,174,p openassistant  the worlds largest opensource replication of chatgpt,0.0
[P] YOLOv4 — The most accurate real-time neural network on MS COCO Dataset,,1252,74,p yolov  the most accurate realtime neural network on ms coco dataset,0.0
[P] Real-time Mask RCNN using Facebook Detectron,,1256,84,p realtime mask rcnn using facebook detectron,0.0
[R] First open source text to video 1.7 billion parameter diffusion model is out,,1242,86,r first open source text to video  billion parameter diffusion model is out,0.0
[N] new SNAPCHAT feature transfers an image of an upper body garment in realtime on a person in AR,,1240,46,n new snapchat feature transfers an image of an upper body garment in realtime on a person in ar,0.0
